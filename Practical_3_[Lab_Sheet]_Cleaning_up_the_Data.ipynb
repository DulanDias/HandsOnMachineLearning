{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practical 3 [Lab Sheet] - Cleaning up the Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQGA0/gG6HT+yeHVA0rmyW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DulanDias/HandsOnMachineLearning/blob/master/Practical_3_%5BLab_Sheet%5D_Cleaning_up_the_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijuiybnH4QEC",
        "colab_type": "text"
      },
      "source": [
        "# **CSC 319 1.5 Machine Learning 1**\n",
        "## **Practical 3 - Cleaning up the Data**\n",
        "\n",
        "In this section, we will continue to work with the California Housing Prices Dataset. The following are the main steps we will go through in this section:\n",
        "1. Data Cleaning\n",
        "2. Handling Text and Categorical Attributes\n",
        "3. Feature Scaling\n",
        "4. Transformation Pipelines\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAcVjvt3safU",
        "colab_type": "text"
      },
      "source": [
        "From the previous practical:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-UDIzJRsdOJ",
        "colab_type": "code",
        "outputId": "08920c1e-da35-42a9-c8d6-e931ee148c84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "\n",
        "import pandas as pd\n",
        "housing = pd.read_csv('https://raw.githubusercontent.com/gurupratap-matharu/machine-learning-regression/master/dataset/housing.csv')\n",
        "\n",
        "def split_train_test(data, test_ratio):\n",
        "  shuffled_indices = np.random.permutation(len(data)) \n",
        "  test_set_size = int(len(data) * test_ratio) \n",
        "  test_indices = shuffled_indices[:test_set_size] \n",
        "  train_indices = shuffled_indices[test_set_size:]\n",
        "  return data.iloc[train_indices], data.iloc[test_indices]\n",
        "\n",
        "train_set, test_set = split_train_test(housing, 0.2)\n",
        "\n",
        "train_set.describe()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>16512.000000</td>\n",
              "      <td>16512.000000</td>\n",
              "      <td>16512.000000</td>\n",
              "      <td>16512.000000</td>\n",
              "      <td>16341.000000</td>\n",
              "      <td>16512.000000</td>\n",
              "      <td>16512.000000</td>\n",
              "      <td>16512.000000</td>\n",
              "      <td>16512.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-119.581770</td>\n",
              "      <td>35.644064</td>\n",
              "      <td>28.601017</td>\n",
              "      <td>2639.296754</td>\n",
              "      <td>538.764580</td>\n",
              "      <td>1424.323825</td>\n",
              "      <td>500.289184</td>\n",
              "      <td>3.874488</td>\n",
              "      <td>207332.326853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.006344</td>\n",
              "      <td>2.141206</td>\n",
              "      <td>12.601003</td>\n",
              "      <td>2182.258031</td>\n",
              "      <td>422.925332</td>\n",
              "      <td>1110.586108</td>\n",
              "      <td>382.783614</td>\n",
              "      <td>1.900277</td>\n",
              "      <td>115886.889856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-124.350000</td>\n",
              "      <td>32.540000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.499900</td>\n",
              "      <td>14999.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-121.810000</td>\n",
              "      <td>33.930000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>1448.000000</td>\n",
              "      <td>296.000000</td>\n",
              "      <td>786.000000</td>\n",
              "      <td>280.000000</td>\n",
              "      <td>2.565075</td>\n",
              "      <td>119400.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-118.515000</td>\n",
              "      <td>34.260000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>2137.000000</td>\n",
              "      <td>436.000000</td>\n",
              "      <td>1169.000000</td>\n",
              "      <td>410.000000</td>\n",
              "      <td>3.531300</td>\n",
              "      <td>179750.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>-118.010000</td>\n",
              "      <td>37.720000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>3146.000000</td>\n",
              "      <td>647.000000</td>\n",
              "      <td>1724.000000</td>\n",
              "      <td>606.000000</td>\n",
              "      <td>4.763900</td>\n",
              "      <td>265900.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>-114.310000</td>\n",
              "      <td>41.950000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>39320.000000</td>\n",
              "      <td>6445.000000</td>\n",
              "      <td>28566.000000</td>\n",
              "      <td>6082.000000</td>\n",
              "      <td>15.000100</td>\n",
              "      <td>500001.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          longitude      latitude  ...  median_income  median_house_value\n",
              "count  16512.000000  16512.000000  ...   16512.000000        16512.000000\n",
              "mean    -119.581770     35.644064  ...       3.874488       207332.326853\n",
              "std        2.006344      2.141206  ...       1.900277       115886.889856\n",
              "min     -124.350000     32.540000  ...       0.499900        14999.000000\n",
              "25%     -121.810000     33.930000  ...       2.565075       119400.000000\n",
              "50%     -118.515000     34.260000  ...       3.531300       179750.000000\n",
              "75%     -118.010000     37.720000  ...       4.763900       265900.000000\n",
              "max     -114.310000     41.950000  ...      15.000100       500001.000000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5LKq2e_uxMP",
        "colab_type": "text"
      },
      "source": [
        "### **1. Data Cleaning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1ZZeH6vruvV",
        "colab_type": "text"
      },
      "source": [
        "Most Machine Learning algorithms cannot work with missing features, so let’s create a few functions to take care of them. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NetcTOTkryVg",
        "colab_type": "text"
      },
      "source": [
        "We noticed earlier that the total_bedrooms attribute has some missing values, so let's fix this. To do this, we have three options:\n",
        "1. Get rid of the corresponding districts\n",
        "2. Get rid of the whole attribute\n",
        "3. Set the value to some value (zero, the mean, the median, etc.)\n",
        "\n",
        "We can accomplish these easily using Pandas DataFrame’s dropna(), drop(), and fillna() methods:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1xOlFjKtA8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# option 1 \n",
        "# YOUR CODE COMES HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Uf6E9Ntt5d2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# option 2\n",
        "# YOUR CODE COMES HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bASTs7LHt-m5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# option 3 \n",
        "# YOUR CODE COMES HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OEQR5sEzlJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE COMES HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNKok9JKusYc",
        "colab_type": "text"
      },
      "source": [
        "On the other hand, SciKit-Learn also provides a very useful class to handle missing values, using SimpleImputer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lefZWAxvckp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE COMES HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAfyg7_wvm4a",
        "colab_type": "text"
      },
      "source": [
        "Since the median can only be calculated on numerical attributes, we need to remove the categorical attributes from our dataset and create another copy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhh0DtcOvvn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE COMES HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4z1KCZ0wil_",
        "colab_type": "text"
      },
      "source": [
        "Now, we can use the fit() method on the imputer instance to our training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5Ul21iH7I7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE COMES HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaeBhjHS7b-M",
        "colab_type": "text"
      },
      "source": [
        "The imputer simply computes the median for each of the numerical attributes and stores it in its own statistics_ instance variable.\n",
        "\n",
        "Eventhough only total_bedrooms had missing values, we cannot be sure of this in a production scenario. Therefore, it is always best to apply the imputer fit() method to all numerical attributes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QheuDSzG8AUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE COMES HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5v61t_K8CuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE COMES HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wU95WQ_8OZB",
        "colab_type": "text"
      },
      "source": [
        "Now we can use this imputer which is aware about the medians of each the numerical attributes, in order to transform the training set by replacing the missing values with the learned medians."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RGnYS8B8bl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE COMES HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WHDRsaR8i1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE COMES HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYcWc5Vj9Aze",
        "colab_type": "text"
      },
      "source": [
        "### **2. Handling Text and Categorical Attributes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWU0GXQ49CRM",
        "colab_type": "text"
      },
      "source": [
        "Earlier we left out the categorical attribute ocean_proximity because it is a text attribute so we cannot compute its median."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXaqM9hgGa97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE COMES HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h78hwytKJjbF",
        "colab_type": "text"
      },
      "source": [
        "#### **Ordinal Encoding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYAuhZIpGtx7",
        "colab_type": "text"
      },
      "source": [
        "Most Machine Learning algorithms prefer to work with numbers. Therefore, let's try to learn convert text to numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEQnCgabGlsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE COMES HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPGJxmwbIazs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE COMES HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQAgmP3dImoG",
        "colab_type": "text"
      },
      "source": [
        "One issue with this type of encoding is that it will assume that two nearby values are more similar than two distant values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Srmof7_vHxbH",
        "colab_type": "text"
      },
      "source": [
        "Categorical data is of two types. Categorical data that are having any intrinsic ordering among themselves are called **Ordinal type**. Categorical data which don’t have any intrinsic ordering among themselves are called **Nominal type**.\n",
        "\n",
        "Some examples of Ordinal Categorical data are:\n",
        "*   Low, Medium, High.\n",
        "*   Agree, Neutral, Disagree.\n",
        "*   Unhappy, Happy, Very Happy.\n",
        "*   Young, Old.\n",
        "\n",
        "Some examples of Nominal Categorical data are:\n",
        "*   Colombo, New York, New Delhi, New Jersey, England.\n",
        "*   Pen, Pencil, Eraser.\n",
        "*   Lion, Monkey, Zebra, Peacock, Elephant.\n",
        "\n",
        "Therefore, ocean_proximity can be identified as a Nominal categorical data, and hence, Ordinal Encoding will not be suitable for our purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrfWEm5aJmIT",
        "colab_type": "text"
      },
      "source": [
        "#### **One Hot Encoding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiB1kkxnJfG4",
        "colab_type": "text"
      },
      "source": [
        "To fix this issue, a common solution is to create one binary attribute per category: \n",
        "one attribute equal to 1 when the category is “<1H OCEAN” (and 0 otherwise), another attribute equal to 1 when the category is “INLAND” (and 0 otherwise), and so on. This is called **one-hot encoding**, because only one attribute will be equal to 1 (hot), while the others will be 0 (cold)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyw3yNN8KRIG",
        "colab_type": "text"
      },
      "source": [
        "Scikit-Learn provides a OneHotEn coder class to convert categorical values into one-hot vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVOMCkcCKS3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE COMES HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu4qVvpALG1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE COMES HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O0swVS2LKiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE COMES HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep7Y40k9LpJ8",
        "colab_type": "text"
      },
      "source": [
        "##### **Embedding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDs_XENOMNae",
        "colab_type": "text"
      },
      "source": [
        "If a categorical attribute has a large number of categories, then one-hot encoding will result in a very large number of features.\n",
        "\n",
        "In this case, we might want to consider replacing the categorical attributes with related and useful numerical attributes. For example, we can replace ocean_proximity to a numerical attribute such as the distance to the ocean.\n",
        "\n",
        "Otherwise, instead of replacing the whole attribute itself, you can replace categories with some learnable low dimensional vector called an **embedding**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg9xWrF5davW",
        "colab_type": "text"
      },
      "source": [
        "### **3. Feature Scaling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHBdq0NCdgwS",
        "colab_type": "text"
      },
      "source": [
        "Traditionally, Machine Learning algorithms do not tend to learn properly when its numerical attributes are in different scales.\n",
        "\n",
        "For example, in the Califonia Housing Prices Dataset, we observed that total number of rooms ranged from 6 to 39,320, while the median incomes only range from 0 to 15.\n",
        "\n",
        "**Note:** Scaling the target value is not required.\n",
        "\n",
        "There are two common methods to get all numerical attributes within the same scale, that is, **min-max scaling** (a.k.a. normalization) and **standardization**."
      ]
    }
  ]
}