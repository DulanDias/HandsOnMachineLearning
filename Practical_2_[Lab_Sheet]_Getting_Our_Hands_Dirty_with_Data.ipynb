{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practical 2 [Lab Sheet] - Getting Our Hands Dirty with Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNbz45s9xTmBvXQcXNZ6/dp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DulanDias/HandsOnMachineLearning/blob/master/Practical_2_%5BLab_Sheet%5D_Getting_Our_Hands_Dirty_with_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijuiybnH4QEC",
        "colab_type": "text"
      },
      "source": [
        "# CSC 319 1.5 Machine Learning 1\n",
        "## Practical 2 [Lab Sheet] - Getting Our Hands Dirty with Data\n",
        "\n",
        "In this section, we will go through an example project related to Real Estates. The following are the main steps we will go through in this section:\n",
        "1. Look at the big picture.\n",
        "2. Get the data.\n",
        "3. Discover and visualize the data to gain insights.\n",
        "4. Prepare the data for Machine Learning algorithms.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B4rLQUN9jgt",
        "colab_type": "text"
      },
      "source": [
        "#### Setup\n",
        "\n",
        "First, let's import a few common modules and check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥ 0.20."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YfZjSpU_iE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSaIaKms_4LB",
        "colab_type": "text"
      },
      "source": [
        "#### Working with Real Data\n",
        "\n",
        "* Popular open data repositories:\n",
        " * [UC Irvine Machine Learning Repository](http://archive.ics.uci.edu/ml/)\n",
        " * [Kaggle datasets](https://www.kaggle.com/datasets)\n",
        " * [Amazon’s AWS datasets](https://registry.opendata.aws/)\n",
        "\n",
        "* Meta portals (they list open data repositories):\n",
        " * http://dataportals.org/\n",
        " * http://opendatamonitor.eu/\n",
        " * http://quandl.com/\n",
        "\n",
        "* Other pages listing many popular open data repositories:\n",
        " * [Wikipedia’s list of Machine Learning datasets](https://homl.info/9)\n",
        " * [Quora.com question](https://homl.info/10)\n",
        " * [Datasets subreddit](https://www.reddit.com/r/datasets)\n",
        "\n",
        "In this section, we will be working with the [California Housing Prices Dataset](https://github.com/gurupratap-matharu/machine-learning-regression/tree/master/dataset).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eJdeVWtCDqZ",
        "colab_type": "text"
      },
      "source": [
        "### 1. Look at the Big Picture\n",
        "\n",
        "Your task is to build a model of housing prices in California using the California census data. This data has metrics such as the population, median income, median housing price, and so on for each block group in California. Block groups are the smallest geographical unit for which the US Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people). We will just call them “districts” for short.\n",
        "\n",
        "Your model should learn from this data and be able to predict the median housing price in any district, given all the other metrics.\n",
        "\n",
        "#### Frame Your Problem\n",
        "\n",
        "First, you need to frame the problem: is it supervised, unsupervised,or Reinforcement Learning? Is it a classification task, a regression task, or something else? Should you use batch learning or online learning techniques?\n",
        "\n",
        "#### Select a Performance Measure\n",
        "\n",
        "A typical performance measure for regression problems is the Root Mean Square Error (RMSE). Another such measure is called, Mean Absolute Error (MAE).\n",
        "Both the RMSE and the MAE are ways to measure the distance between two vectors: the vector of predictions and the vector of target values.\n",
        "RMSE is more sensitive to outliers than MAE. But when outliers are expotentially rare, the RMSE performs very well and is generally preferred.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkOQCwSNPpsz",
        "colab_type": "text"
      },
      "source": [
        "### 2. Get the Data\n",
        "\n",
        "You can find the hosted dataset here: https://github.com/gurupratap-matharu/machine-learning-regression/blob/master/dataset/housing.csv\n",
        "\n",
        "You are required to:\n",
        "1. Read the data from the above URL and store it in a variable.\n",
        "2. Print the top most five rows in your loaded dataset (HINT: using head() method)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87QP6HeHQQmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE SHOULD COME HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmW-ZsNbeVQy",
        "colab_type": "text"
      },
      "source": [
        "### 3. Discover and visualize the data to gain insights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxSBf1ZARayv",
        "colab_type": "text"
      },
      "source": [
        "The info() method is useful to get a quick description of the data, in particular the total number of rows, and each attribute’s type and number of non-null values.\n",
        "\n",
        "You are required to:\n",
        "1. Use the info() method to find out the type of data fields present in our dateset and identify fields with null values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8vt68Q6Rgza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE SHOULD COME HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAcaL_WGTJAO",
        "colab_type": "text"
      },
      "source": [
        "Note: The total_bedrooms attribute has only 20433 non-null values while all the rest of the attributes have 20640 non-null values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSMlkklnIMT3",
        "colab_type": "text"
      },
      "source": [
        "When you looked at the top five rows, you probably noticed that the values in the ocean_proximity column were repetitive, which means that it is probably a categorical attribute, while the rest are numerical attributes.\n",
        "\n",
        "You are required to:\n",
        "1. Find out call the different categories of values for the 'ocean_proximity' data column, and count the number of values for each category, using the value_counts() method.\n",
        "2. Using the describe() method, find a summary of the numerical attributes of your dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc9bPhaGIlBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE SHOULD COME HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-HXIIZKLhqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE SHOULD COME HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgvEttmwLvWq",
        "colab_type": "text"
      },
      "source": [
        "Note: The describe() method has ignored the null values in the total_bedrooms data column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiQK1AXYZx6A",
        "colab_type": "text"
      },
      "source": [
        "Another great way to get a feel of the data is to visualize it through a histogram.\n",
        "\n",
        "You are required to:\n",
        "1. Draw a histogram plot for each of the numerical attributes using the whole dataset in one single plot.\n",
        "2. Draw histogram plots for each of the numerical attributes using the whole dataset using one plot each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt_AxQMfagfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE SHOULD COME HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg0blFRWQD4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE SHOULD COME HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo8rUK6ceb8y",
        "colab_type": "text"
      },
      "source": [
        "Sometimes, our data may have outliers. This can cause a huge mess when we are training our machine learning algorithm.\n",
        "\n",
        "One of the best plots that we can draw to visualize outliers, is a Box and Whisker plot.\n",
        "\n",
        "You are required to:\n",
        "1. Draw a Box and Whisker plot for the numerical attributes of our dataset.\n",
        "2. Draw a Scatter plot for longitude and latitude columns of our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgdWU39Af0LI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE SHOULD COME HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnHkIIGPiSXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE SHOULD COME HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtVgiMeMioCh",
        "colab_type": "text"
      },
      "source": [
        "Now that’s much better: you can clearly see the high-density areas, namely the Bay Area and around Los Angeles and San Diego, plus a long line of fairly high density in the Central Valley, in particular around Sacramento and Fresno."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKGToEiQiqID",
        "colab_type": "text"
      },
      "source": [
        "Our brain is very good at visualizing patterns on pictures. But we need to properly prepare the paramaters to generate proper visualizations that can portray valuable details.\n",
        "\n",
        "Now let’s look at the housing prices. The radius of each circle represents the district’s population (option s), and the color represents the price (option c). We will use a predefined color map (option cmap) called jet, which ranges from blue (low values) to red (high prices)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaqxEQWti8fn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
        "        s=housing[\"population\"]/100, label=\"population\", figsize=(10,7),\n",
        "        c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
        ")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9lFN8cMjDHT",
        "colab_type": "text"
      },
      "source": [
        "This image tells you that the housing prices are very much related to the location and to the population density."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AryuQQkrjPm-",
        "colab_type": "text"
      },
      "source": [
        "#### Looking for Correlations\n",
        "\n",
        "Since the dataset is not too large, we can easily compute the 'standard correlation coefficient' between every pair of attributes, using the corr() method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2FAnn_1kCxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr_matrix = housing.corr()\n",
        "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aOriQg6Q7-y",
        "colab_type": "text"
      },
      "source": [
        "Another way to check for correlation between attributes can be done using a scatter_matrix function provided by the pandas package, which plots every numerical attribute against every other numerical attribute.\n",
        "\n",
        "Since there are now 11 numerical attributes, you would get 11^2 = 121 plots, which would not fit on a page, so let’s just focus on a few promising attributes that seem most correlated with the median housing value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PeWuxtBRajI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\", \"housing_median_age\"]\n",
        "scatter_matrix(housing[attributes], figsize=(12, 8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmXY45_zR_2o",
        "colab_type": "text"
      },
      "source": [
        "Let's zoom in to the plot between median_income and median_house_value.\n",
        "\n",
        "You are required to: \n",
        "1. Draw a scatter plot between median_income and median_house_value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF4HGuB7SFch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE SHOULD COME HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DncG-vngTt0",
        "colab_type": "text"
      },
      "source": [
        "### 4. Prepare the data for Machine Learning algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqrM-h_OgWQX",
        "colab_type": "text"
      },
      "source": [
        "#### Create a Test and Train Subsets\n",
        "\n",
        "Creating a test set is theoretically quite simple: just pick some instances randomly, typically 20% of the dataset (or less if your dataset is very large), and set them aside."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXZYZAOXg0y1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_train_test(data, test_ratio):\n",
        "  shuffled_indices = np.random.permutation(len(data)) \n",
        "  test_set_size = int(len(data) * test_ratio) \n",
        "  test_indices = shuffled_indices[:test_set_size] \n",
        "  train_indices = shuffled_indices[test_set_size:]\n",
        "  return data.iloc[train_indices], data.iloc[test_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsQjXC4ZhCsi",
        "colab_type": "text"
      },
      "source": [
        "You are required to:\n",
        "1. Create two subsets of your dataset, with 20% randomly chosen data rows as the test_set and the rest as train_set.\n",
        "2. View the size of the train_set and test_set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYNo5_UFhBR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE SHOULD COME HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_70YA3mohUNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE SHOULD COME HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVzFDun8hW02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE SHOULD COME HERE"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}